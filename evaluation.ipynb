{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "zn_TWrb4hwzk",
   "metadata": {
    "id": "zn_TWrb4hwzk"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb51339-45ea-435c-a2ff-f3eac9e9a6d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "4fb51339-45ea-435c-a2ff-f3eac9e9a6d4",
    "outputId": "3d75b2c0-76ae-4436-cf89-d6e64232753c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import gdown\n",
    "from keras.models import load_model\n",
    "from tqdm.notebook import tqdm\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4Im6l__Bh0HI",
   "metadata": {
    "id": "4Im6l__Bh0HI"
   },
   "outputs": [],
   "source": [
    "model = DeepFace.build_model(\"DeepFace\")\n",
    "model.model = tf.keras.models.load_model(\"deepface_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NzFE1iu_f8m1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NzFE1iu_f8m1",
    "outputId": "8cd61c00-4c67-4b39-bbe7-3d0d53ce7caf"
   },
   "outputs": [],
   "source": [
    "test_ds = image_dataset_from_directory(\n",
    "    \"test_aligned\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    image_size=(152, 152),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nq6wAznRWswy",
   "metadata": {
    "id": "Nq6wAznRWswy"
   },
   "outputs": [],
   "source": [
    "# we can move it to utils file\n",
    "\n",
    "def load_database(path):\n",
    "    dataset = {}\n",
    "    for person in os.listdir(path):\n",
    "        person_name = person.split(\".\")[0]\n",
    "        dataset[person_name] = np.load(os.path.join(path, person))\n",
    "    return dataset\n",
    "\n",
    "def get_average_embedding(path):\n",
    "    total_embeddings = None\n",
    "    for img in os.listdir(path):\n",
    "        image = cv2.imread(os.path.join(path, img))\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        try:\n",
    "            detected_face_embedding = model.find_embeddings(image)\n",
    "        except:\n",
    "            continue\n",
    "        if total_embeddings is None:\n",
    "            total_embeddings = detected_face_embedding\n",
    "        else:\n",
    "            total_embeddings = np.vstack((total_embeddings, detected_face_embedding))\n",
    "    return np.mean(total_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g0ab2IHbjDy8",
   "metadata": {
    "id": "g0ab2IHbjDy8"
   },
   "outputs": [],
   "source": [
    "test_dataset = load_database(\"test_database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64715a-5a57-4b2b-a752-50b59abf2cc9",
   "metadata": {
    "id": "2b64715a-5a57-4b2b-a752-50b59abf2cc9"
   },
   "source": [
    "## Luminance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xnzd-qm1abTn",
   "metadata": {
    "id": "Xnzd-qm1abTn"
   },
   "outputs": [],
   "source": [
    "def scale_luminance(image, method, factor=None):\n",
    "    image_yuv = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "    y = image_yuv[:,:,0]\n",
    "\n",
    "    if method == \"square\":\n",
    "      y = np.clip(y ** 2, 0, 255).astype(np.uint8)\n",
    "    if method == \"linear\":\n",
    "      y = np.clip(y * factor, 0, 255).astype(np.uint8)\n",
    "    if method == \"const\":\n",
    "      y = np.clip(y + factor, 0, 255).astype(np.uint8)\n",
    "\n",
    "    image_yuv[:,:,0] = y\n",
    "    image = cv2.cvtColor(image_yuv, cv2.COLOR_YUV2RGB)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jopkljxSgFPf",
   "metadata": {
    "id": "jopkljxSgFPf"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mKSQVaXwXVwX",
   "metadata": {
    "id": "mKSQVaXwXVwX"
   },
   "outputs": [],
   "source": [
    "test_paths = os.listdir(\"test_aligned\")\n",
    "test_paths = [os.path.join(\"test_aligned\", path) for path in test_paths if not path.startswith(\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drnM0fSwZnor",
   "metadata": {
    "id": "drnM0fSwZnor"
   },
   "outputs": [],
   "source": [
    "test_image = cv2.imread(os.path.join(test_paths[0], os.listdir(test_paths[0])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4Dxx5EXwdDHZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "4Dxx5EXwdDHZ",
    "outputId": "eb4962e5-5a07-40e9-e773-d3c2ca1ba06b"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 6, figsize=(14, 10))\n",
    "\n",
    "axes[0].imshow(test_image)\n",
    "axes[1].imshow(scale_luminance(test_image, \"square\"))\n",
    "axes[2].imshow(scale_luminance(test_image, \"linear\", 0.5))\n",
    "axes[3].imshow(scale_luminance(test_image, \"linear\", 1.5))\n",
    "axes[4].imshow(scale_luminance(test_image, \"const\", -100))\n",
    "axes[5].imshow(scale_luminance(test_image, \"const\", 30))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8FkQT09TgJ9G",
   "metadata": {
    "id": "8FkQT09TgJ9G"
   },
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07b2c5-a4de-413a-b2a0-647e0a0645b3",
   "metadata": {
    "id": "fc07b2c5-a4de-413a-b2a0-647e0a0645b3"
   },
   "outputs": [],
   "source": [
    "PARAMS = [(\"linear\", 1/2), (\"linear\", 3/5), (\"linear\", 3/4), (\"linear\", 4/3), (\"linear\", 3/2),\n",
    "          (\"const\", -100), (\"const\", -20), (\"const\", -10), (\"const\", 30)]\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    for img, label in zip(images, labels):\n",
    "        for param in PARAMS:\n",
    "          img_to_model = scale_luminance(img.numpy(), param)\n",
    "          img_to_model = tf.expand_dims(img_to_model, axis=0)\n",
    "          try:\n",
    "              detected_face_embedding = model.find_embeddings(img_to_model)\n",
    "          except:\n",
    "              continue\n",
    "          distances = []\n",
    "          for person in test_dataset:\n",
    "              distances.append(np.linalg.norm(detected_face_embedding - test_dataset[person]))\n",
    "          if np.argmin(distances) == label:\n",
    "              correct += 1\n",
    "          total += 1\n",
    "\n",
    "correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be15f9c-3318-44ed-8c7f-e4476485e795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
